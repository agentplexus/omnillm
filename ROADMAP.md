# OmniLLM Roadmap

This roadmap documents planned and completed features for this project.

The format is based on and generated by [Structured Roadmap](https://github.com/grokify/structured-roadmap), which provides a machine-readable JSON intermediate representation with deterministic Markdown generation.

## Overview

| Item | Status | Priority | Area |
|------|--------|----------|------|
| Retry with Backoff | âœ… | High Priority | Reliability |
| Request Timeouts | âœ… | High Priority | Client Features |
| Extended Sampling Parameters | âœ… | High Priority | Client Features |
| Fallback Providers | ðŸ“‹ | High Priority | Reliability |
| Circuit Breaker | ðŸ“‹ | High Priority | Reliability |
| Token Counting/Estimation | ðŸ“‹ | High Priority | Performance |
| Response Caching | ðŸ“‹ | High Priority | Performance |
| Rate Limiting | ðŸ“‹ | Medium Priority | Reliability |
| Testing | ðŸ“‹ | Medium Priority | Testing |
| Documentation | ðŸ“‹ | Medium Priority | Documentation |
| Infrastructure | ðŸ“‹ | Medium Priority | Infrastructure |
| Code Quality | ðŸ“‹ | Medium Priority | Testing |
| Embeddings API | ðŸ’¡ | Low Priority | API Extensions |
| Structured Output Validation | ðŸ’¡ | Low Priority | API Extensions |
| Batch Processing | ðŸ’¡ | Low Priority | API Extensions |

---

## Table of Contents

- [Client Features (2/2)](#client-features)
- [Reliability (1/4)](#reliability)
- [Performance (0/2)](#performance)
- [Testing (0/2)](#testing)
- [Documentation (0/1)](#documentation)
- [Infrastructure (0/1)](#infrastructure)
- [API Extensions (0/3)](#api-extensions)
- [Design Decisions](#design-decisions)

---

## Client Features

### [x] Request Timeouts

Per-request timeout configuration.

**Version:** 0.10.0

Implemented via `ClientConfig.Timeout`.

```go
ClientConfig{
    Timeout: 300 * time.Second,  // Recommended for reasoning models
}
```

### [x] Extended Sampling Parameters

Additional sampling and generation parameters beyond Temperature and TopP.

**Version:** 0.11.0

Implemented via `ChatCompletionRequest` fields.

| Parameter | Providers | Description |
|--------|--------|--------|
| `TopK` | Anthropic, Gemini, Ollama | Limits token selection to top K candidates |
| `Seed` | OpenAI, X.AI, Ollama | Enables reproducible outputs |
| `N` | OpenAI | Number of completions to generate |
| `ResponseFormat` | OpenAI, Gemini | JSON mode (`{"type": "json_object"}`) |
| `Logprobs` | OpenAI | Return log probabilities of output tokens |
| `TopLogprobs` | OpenAI | Number of most likely tokens to return |

```go
req := &omnillm.ChatCompletionRequest{
    Model:    omnillm.ModelGPT4o,
    Messages: messages,
    TopK:     ptr(40),                                    // Anthropic, Gemini, Ollama
    Seed:     ptr(42),                                    // OpenAI, X.AI, Ollama
    ResponseFormat: &omnillm.ResponseFormat{Type: "json_object"}, // OpenAI, Gemini
}
```

---

## Reliability

### [x] Retry with Backoff

Automatic retries for transient failures (rate limits, 5xx errors).

**Version:** 0.7.0

Implemented via `ClientConfig.HTTPClient` with `retryhttp.RetryTransport`.

```go
rt := retryhttp.NewWithOptions(
    retryhttp.WithMaxRetries(5),
    retryhttp.WithInitialBackoff(500 * time.Millisecond),
)
client, err := omnillm.NewClient(omnillm.ClientConfig{
    Provider:   omnillm.ProviderNameOpenAI,
    APIKey:     "...",
    HTTPClient: &http.Client{Transport: rt},
})
```

### [ ] Fallback Providers

Automatic failover when primary provider fails.

```go
ClientConfig{
    Provider: omnillm.ProviderNameOpenAI,
    FallbackProviders: []ProviderConfig{
        {Provider: omnillm.ProviderNameAnthropic, APIKey: "..."},
    },
}
```

### [ ] Circuit Breaker

Prevent cascading failures when provider is unhealthy.

### [ ] Rate Limiting

Client-side rate limiter to respect provider limits.

---

## Performance

### [ ] Token Counting/Estimation

Estimate tokens before sending to avoid limit errors.

### [ ] Response Caching

Cache identical requests to reduce costs (with TTL).

---

## Testing

### [ ] Testing

Expand test coverage and improve testing infrastructure.

- [ ] **Expand test coverage** - Integration tests currently require API keys; consider adding more mock-based unit tests
- [ ] **Add streaming tests** - Some providers lack comprehensive streaming response tests
- [ ] **Provider parity testing** - Ensure all providers have equivalent test coverage

### [ ] Code Quality

Code quality and consistency enhancements.

- [ ] **Consistent error wrapping** - Ensure all errors include sufficient context
- [ ] **Interface compliance tests** - Add compile-time checks for provider interface compliance
- [ ] **Benchmarks** - Add performance benchmarks for critical paths

---

## Documentation

### [ ] Documentation

Improve documentation coverage and quality.

- [ ] **Error type documentation** - More comprehensive docs on error types and handling patterns
- [ ] **Provider-specific quirks** - Document provider differences and edge cases
- [ ] **Migration guides** - Add guides for migrating from provider-specific SDKs

---

## Infrastructure

### [ ] Infrastructure

CI/CD and build infrastructure enhancements.

- [ ] **CI/CD pipeline** - Add GitHub Actions workflows for automated testing, linting, and releases
- [ ] **Coverage reporting** - Integrate coverage badges and reports into CI
- [ ] **Cross-platform testing** - Verify builds on Linux, macOS, and Windows

---

## API Extensions

### [ ] Embeddings API

Unified interface for text embeddings.

### [ ] Structured Output Validation

JSON schema validation for responses.

### [ ] Batch Processing

Efficient batch request handling.

---

## Design Decisions

The following design decisions guide feature prioritization:

| Question | Decision | Impact |
|--------|--------|--------|
| Primary use case | General-purpose SDK (chatbot, batch, real-time) | Support all use cases equally; no single-use-case optimizations |
| Cost optimization | High priority | Elevated token counting and response caching to high priority |
| Uptime/reliability | Critical | Elevated circuit breaker to high priority; fallback providers already high |
