# Changelog

All notable changes to OmniLLM are documented in the individual release notes.

## Releases

| Version | Date | Highlights |
|---------|------|------------|
| [v0.12.0](v0.12.0.md) | 2026-02-22 | Tool/function calling support for OpenAI |
| [v0.11.0](v0.11.0.md) | 2026-01-10 | Multi-provider configuration, Grok 4 models |
| [v0.10.0](v0.10.0.md) | 2026-01-04 | Response caching, token estimation |
| [v0.9.0](v0.9.0.md) | 2026-01-04 | Circuit breaker, fallback providers |
| [v0.8.0](v0.8.0.md) | 2026-01-04 | Observability hooks |
| [v0.7.0](v0.7.0.md) | 2025-12-26 | Conversation memory, X.AI provider |
| [v0.6.0](v0.6.0.md) | 2025-12-26 | External provider support, Bedrock |

## Versioning

OmniLLM follows [Semantic Versioning](https://semver.org/):

- **MAJOR**: Breaking API changes
- **MINOR**: New features (backwards compatible)
- **PATCH**: Bug fixes (backwards compatible)

## Full Changelog

See [CHANGELOG.md](https://github.com/agentplexus/omnillm/blob/main/CHANGELOG.md) for the complete changelog in Keep a Changelog format.
